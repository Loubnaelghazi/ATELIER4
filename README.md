# Objective : The main purpose behind this lab is to get familiar with NLP language models
using Pytorch library.

## Overview
This LAB involves 3 parts :
Part1 Classification /Regression
Part 2 Transformer (Text generation)
Part 3 BERT

## Table of Contents
1. [Part 1](#Part 1)
2. [Part 2](#Part 2)
3. [Part 3](#Part 3)
4. [Acknowledgements](#Acknowledgements)

## Part 1
The preprocessing pipeline includes:
- Tokenization
- Stemming
- Lemmatization
- Stop words removal
- Text discretization

## Part 2
This part aims to fine-tune the pre-trained GPT-2 model on a custom dataset and generate text based on a given prompt.


## Part 3
For regression tasks, I trained:
- Support Vector Regression (SVR)
- Naive Bayes
- Linear Regression
- Decision Tree

For classification tasks, I trained:
- Support Vector Machine (SVM)
- Naive Bayes
- Logistic Regression
- Ada Boosting



## Acknowledgements
Special thanks to Pr. Elaachak Lotfi for his guidance and support throughout this project.
